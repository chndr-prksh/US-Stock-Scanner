{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gspread\n",
    "import talib as ta\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "df_nyse_holidays = pd.read_csv(\"nyse_holidays.csv\")\n",
    "nyse_holidays = [dt.datetime.strptime(date, \"%d-%b-%y\").date() for date in df_nyse_holidays['Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from tiingo import TiingoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "\n",
    "# To reuse the same HTTP Session across API calls (and have better performance), include a session key.\n",
    "config['session'] = True\n",
    "\n",
    "# If you don't have your API key as an environment variable,\n",
    "# pass it in via a configuration dictionary.\n",
    "config['api_key'] = '4faa12a9eeb4da65c763258897ab593545f98f00'\n",
    "#cp \"5d58df57a94d667b0fdbb57d81828680e1d8f14a\"\n",
    "#gmail main \"6e0dfa8bf5a18b3a5167ad5fdc8f2f438c136b18\"\n",
    "\n",
    "# Initialize\n",
    "client = TiingoClient(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get previous trading day\n",
    "from datetime import date, timedelta\n",
    "def prev_weekday(adate):\n",
    "    adate -= timedelta(days=1)\n",
    "    while ((adate.weekday() > 4) & (adate not in nyse_holidays)):\n",
    "        # Mon-Fri are 0-4 #also add holidays to this\n",
    "        adate -= timedelta(days=1)\n",
    "    return adate\n",
    "\n",
    "# str(prev_weekday(date.today()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_(dataframe,days = 20):\n",
    "    dataframe['Trend+'] = (dataframe['Smooth_+DX']>dataframe['Smooth_-DX']).astype(int)\n",
    "    dataframe['Trend-'] = (dataframe['Smooth_-DX']>dataframe['Smooth_+DX']).astype(int)\n",
    "    if(np.sum(dataframe['Trend+'])==len(dataframe['Trend+'])):\n",
    "        return('uptrend')\n",
    "    elif(np.sum(dataframe['Trend-'])==len(dataframe['Trend-'])):\n",
    "        return('downtrend')\n",
    "    else:\n",
    "        return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import compress\n",
    "from candle_rankings import candle_rankings\n",
    "def recognize_candlestick(df):\n",
    "    candles = ta.get_function_groups()['Pattern Recognition']\n",
    "    exclude_items = ('CDLCOUNTERATTACK',\n",
    "                     'CDLLONGLINE',\n",
    "                     'CDLSHORTLINE',\n",
    "                     'CDLSTALLEDPATTERN',\n",
    "                     'CDLKICKINGBYLENGTH')\n",
    "    candle_names = [candle for candle in candles if candle not in exclude_items]\n",
    "    op = df['Open']\n",
    "    hi = df['High']\n",
    "    lo = df['Low']\n",
    "    cl = df['Close']\n",
    "\n",
    "    for candle in candle_names:\n",
    "        df[candle] = getattr(ta, candle)(op, hi, lo, cl)\n",
    "\n",
    "\n",
    "    df['candlestick_pattern'] = np.nan\n",
    "    df['candlestick_match_count'] = np.nan\n",
    "    for index, row in df.iterrows():\n",
    "        # no pattern found\n",
    "        if len(row[candle_names]) - sum(row[candle_names] == 0) == 0:\n",
    "            df.loc[index,'candlestick_pattern'] = \"\"\n",
    "            df.loc[index, 'candlestick_match_count'] = 0\n",
    "        # single pattern found\n",
    "        elif len(row[candle_names]) - sum(row[candle_names] == 0) == 1:\n",
    "            # bull pattern 100 or 200\n",
    "            if any(row[candle_names].values > 0):\n",
    "                pattern = list(compress(row[candle_names].keys(), row[candle_names].values != 0))[0] + '_Bull'\n",
    "                df.loc[index, 'candlestick_pattern'] = pattern\n",
    "                df.loc[index, 'candlestick_match_count'] = 1\n",
    "            # bear pattern -100 or -200\n",
    "            else:\n",
    "                pattern = list(compress(row[candle_names].keys(), row[candle_names].values != 0))[0] + '_Bear'\n",
    "                df.loc[index, 'candlestick_pattern'] = pattern\n",
    "                df.loc[index, 'candlestick_match_count'] = 1\n",
    "        # multiple patterns matched -- select best performance\n",
    "        else:\n",
    "            # filter out pattern names from bool list of values\n",
    "            patterns = list(compress(row[candle_names].keys(), row[candle_names].values != 0))\n",
    "            container = []\n",
    "            for pattern in patterns:\n",
    "                if row[pattern] > 0:\n",
    "                    container.append(pattern + '_Bull')\n",
    "                else:\n",
    "                    container.append(pattern + '_Bear')\n",
    "            rank_list = [candle_rankings[p] for p in container]\n",
    "            if len(rank_list) == len(container):\n",
    "                rank_index_best = rank_list.index(min(rank_list))\n",
    "                df.loc[index, 'candlestick_pattern'] = container[rank_index_best]\n",
    "                df.loc[index, 'candlestick_match_count'] = len(container)\n",
    "    # clean up candle columns\n",
    "    cols_to_drop = candle_names\n",
    "    df.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsi_infer(rsi):\n",
    "    if(rsi>70):\n",
    "        return \"Overbought\"\n",
    "    elif((rsi>50) & (rsi<=70)):\n",
    "        return \"Bullish\"\n",
    "    elif((rsi<=50) & (rsi>30)):\n",
    "        return \"Bearish\"\n",
    "    elif(rsi<=30):\n",
    "        return \"Oversold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock):\n",
    "    stock = stock.upper()\n",
    "    a = client.get_dataframe(stock, startDate=str(prev_weekday(date.today())-timedelta(weeks=52)),\n",
    "                                      endDate=str(date.today()), \n",
    "                                      frequency='daily')\n",
    "    a['Stock Name'] =stock\n",
    "    \n",
    "    a = a[['Stock Name','adjClose', 'adjHigh', 'adjLow', 'adjOpen', 'adjVolume']]\n",
    "    a.columns = ['Stock Name','Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    a.columns = ['Stock Name','Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    inputs_ta = {\n",
    "        'open': a['Open'],\n",
    "        'high': a['Close'],\n",
    "        'low': a['Low'],\n",
    "        'close': a['Close'],\n",
    "        'volume': a['Volume']\n",
    "    }\n",
    "    a['RSI'] = ta.RSI(inputs_ta['close'], timeperiod=14)\n",
    "    a['RSI_infer'] = a['RSI'].apply(lambda x: get_rsi_infer(x))\n",
    "    a['upper_bollinger'], a['middle_bollinger'], a['lower_bollinger'] = ta.BBANDS(inputs_ta['close'], \n",
    "                                                                                     matype=ta.MA_Type.T3)\n",
    "    a['MACD'],a['macdsignal'], a['macdhist'] = ta.MACD(inputs_ta['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    a.drop(['macdsignal', 'macdhist'], axis=1,inplace= True)\n",
    "    a['Plus_DI']=ta.PLUS_DI(inputs_ta['high'], inputs_ta['low'], inputs_ta['close'], timeperiod=14)\n",
    "    a['Minus_DI']=ta.MINUS_DI(inputs_ta['high'], inputs_ta['low'], inputs_ta['close'], timeperiod=14)\n",
    "    a['ADX'] = ta.ADX(inputs_ta['high'], inputs_ta['low'], inputs_ta['close'], timeperiod=14)\n",
    "    a['CCI'] = ta.CCI(inputs_ta['high'], inputs_ta['low'], inputs_ta['close'], timeperiod=14)\n",
    "    a['WILLR'] = ta.WILLR(inputs_ta['high'], inputs_ta['low'], inputs_ta['close'], timeperiod=14)\n",
    "    a['Prev Close'] = a['Close'].shift(1)\n",
    "    a['high_minus_low'] = a['High'] - a['Low']\n",
    "    a['high_minus_prev_close'] = a['High'] - a['Prev Close']\n",
    "    a['low_minus_prev_close'] = a['Low'] - a['Prev Close']\n",
    "    a['Prev High'] = a['High'].shift(1)\n",
    "    a['High_minus_Prev_High'] = a['High'] - a['Prev High']\n",
    "    a['Prev Low'] = a['Low'].shift(1)\n",
    "    a['Prev_Low_minus_Low'] = a['Prev Low'] - a['Low']\n",
    "\n",
    "    a['+DX'] = a.apply(lambda x: x['High_minus_Prev_High'] if((x['High_minus_Prev_High']>x['Prev_Low_minus_Low']) & \n",
    "                                                              (x['High_minus_Prev_High']>0)) else 0, axis = 1)\n",
    "    a['-DX'] = a.apply(lambda x: x['Prev_Low_minus_Low'] if((x['Prev_Low_minus_Low']>x['High_minus_Prev_High']) & \n",
    "                                                            (x['Prev_Low_minus_Low']>0)) else 0, axis = 1)\n",
    "    a['Smooth_+DX'] = a['+DX'].rolling(window = 14, min_periods = 14).mean()\n",
    "    a['Smooth_-DX'] = a['-DX'].rolling(window = 14, min_periods = 14).mean()\n",
    "    trend_stock = trend_(a.tail(20))\n",
    "    \n",
    "    b = a.iloc[-1]\n",
    "    temp = pd.DataFrame(b.T.reset_index().T.values[1:],columns = b.T.reset_index().T.values[0])\n",
    "    b['Candlestick_Pattern'] = recognize_candlestick(temp[['Open','High','Low','Close']])['candlestick_pattern'].values[0]\n",
    "\n",
    "    b['Trend'] = trend_stock\n",
    "    b['20_D_Avg_Vol'] = np.average(a.tail(20)['Volume'])\n",
    "    b['10_D_Avg_Vol'] = np.average(a.tail(10)['Volume'])\n",
    "    b['5_D_Avg_Vol'] = np.average(a.tail(5)['Volume'])\n",
    "\n",
    "    b['200_D_Avg_Close'] = np.average(a.tail(200)['Close'])\n",
    "    b['50_D_Avg_Close'] = np.average(a.tail(50)['Close'])\n",
    "    b['20_D_Avg_Close'] = np.average(a.tail(20)['Close'])\n",
    "    b['5_D_Avg_Close'] = np.average(a.tail(5)['Close'])\n",
    "    \n",
    "    b['Prv_200_D_Avg_Close'] = np.average(a.tail(201)[1:200]['Close'])\n",
    "    b['Prv_50_D_Avg_Close'] = np.average(a.tail(51)[1:50]['Close'])\n",
    "    b['Prv_20_D_Avg_Close'] = np.average(a.tail(21)[1:20]['Close'])\n",
    "\n",
    "    \n",
    "    b['120_D_Max_Close'] = np.max(a.tail(120)['Close'])\n",
    "    b['20_D_Max_Close'] = np.max(a.tail(20)['Close'])\n",
    "    b['5_D_Max_Close'] = np.average(a.tail(5)['Close'])\n",
    "\n",
    "    b['Yr_H_Price'] = np.max(a['High'])\n",
    "    b['Yr_L_Price'] = np.min(a['Low'])\n",
    "    b['Yr_H_Vol'] = np.max(a['Volume'])\n",
    "    b['Yr_L_Vol'] = np.min(a['Volume'])\n",
    "    \n",
    "    b['Prv_Yr_H_Price'] = np.max(a[:-1]['High'])\n",
    "    b['Prv_Yr_L_Price'] = np.min(a[:-1]['Low'])\n",
    "    b['Prv_Yr_H_Vol'] = np.max(a[:-1]['Volume'])\n",
    "    b['Prv_Yr_L_Vol'] = np.min(a[:-1]['Volume'])\n",
    "    \n",
    "    b['Prv_2_Close'] = a.iloc[-3]['Close']\n",
    "    b['Prv_3_Close'] = a.iloc[-4]['Close']\n",
    "    \n",
    "    b['Prv_1_Open'] = a.iloc[-2]['Open']\n",
    "    b['Prv_2_Open'] = a.iloc[-3]['Open']\n",
    "    b['Prv_3_Open'] = a.iloc[-4]['Open']\n",
    "\n",
    "    b['Prv_1_Low'] = a.iloc[-2]['Low']\n",
    "    b['Prv_2_Low'] = a.iloc[-3]['Low']\n",
    "    b['Prv_3_Low'] = a.iloc[-4]['Low']\n",
    "    b['Prv_4_Low'] = a.iloc[-5]['Low']\n",
    "    b['Prv_5_Low'] = a.iloc[-6]['Low']\n",
    "    b['Prv_6_Low'] = a.iloc[-7]['Low']\n",
    "    b['Prv_7_Low'] = a.iloc[-8]['Low']\n",
    "    b['Prv_8_Low'] = a.iloc[-9]['Low']\n",
    "    b['10_D_Min_Low'] = np.min(a.tail(10)['Low'])\n",
    "    b['50_D_Min_Low'] = np.min(a.tail(50)['Low'])\n",
    "\n",
    "    b['Prv_1_High'] = a.iloc[-2]['High']\n",
    "    b['Prv_2_High'] = a.iloc[-3]['High']\n",
    "    b['Prv_3_High'] = a.iloc[-4]['High']\n",
    "    b['Prv_4_High'] = a.iloc[-5]['High']\n",
    "    b['Prv_5_High'] = a.iloc[-6]['High']\n",
    "    b['Prv_6_High'] = a.iloc[-7]['High']\n",
    "    b['Prv_7_High'] = a.iloc[-8]['High']\n",
    "    b['Prv_8_High'] = a.iloc[-9]['High']\n",
    "    b['10_D_Max_High'] = np.max(a.tail(10)['High'])\n",
    "    b['50_D_Max_High'] = np.max(a.tail(50)['High'])\n",
    "    \n",
    "    b['100_D_Avg_Range'] = np.mean(a.tail(100)['High']-a.tail(100)['Low'])\n",
    "    b['Prev_Volume'] = a.iloc[-2]['Volume']\n",
    "    \n",
    "    b = pd.DataFrame(b.T.reset_index().T.values[1:],columns = b.T.reset_index().T.values[0])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ = pd.DataFrame()\n",
    "# df_['Open'] = [307.71]\n",
    "# df_['High'] = [307.9]\n",
    "# df_['Low'] = [300.21]\n",
    "# df_['Close'] = [300.35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_stocks = pd.read_excel(\"us_stocks.xlsx\",header=0,sheet_name=\"us_stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "token = 'AAHwf08vrNDxf_zEl-Ri0hDESHvGM_WIaok'\n",
    "method = 'sendMessage'\n",
    "response = requests.post(\n",
    "    url='https://api.telegram.org/bot1216810091:{0}/{1}'.format(token, method),\n",
    "    data={'chat_id': -444135572, 'text': \"US stock scanning started for {0}\".format(str(date.today()))}).json()\n",
    "# :AAHwf08vrNDxf_zEl-Ri0hDESHvGM_WIaok/sendMessage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3160b450078f446788ca0f416a967787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=451.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "stock_data_us = pd.DataFrame(columns = ['Stock Name', 'Open','High','Low','Close','Prev Close',\n",
    "                                         'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                                         '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                                         'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                                         '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                                         '50_D_Max_High','10_D_Max_High',\n",
    "                                         'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                                         '50_D_Min_Low','10_D_Min_Low',\n",
    "                                         'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                                         '100_D_Avg_Range',\n",
    "                                         'Yr_H_Vol','Yr_L_Vol',\n",
    "                                         '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                                         'Volume','Prev_Volume',\n",
    "                                         'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                                         'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                                         'Prv_8_High','Prv_8_Low',\n",
    "                                        'Candlestick_Pattern', 'RSI',\n",
    "                                        'upper_bollinger','middle_bollinger','lower_bollinger',\n",
    "                                        'Plus_DI','Minus_DI','ADX','MACD','CCI','WILLR'\n",
    "                                       ])\n",
    "\n",
    "stock_names = us_stocks['Symbol']\n",
    "\n",
    "for stock in tqdm(stock_names):\n",
    "    try:\n",
    "        temp = get_stock_data(stock)\n",
    "        temp = temp[['Stock Name', 'Open','High','Low','Close','Prev Close',\n",
    "                     'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                     '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                     'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                     '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                     '50_D_Max_High','10_D_Max_High',\n",
    "                     'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                     '50_D_Min_Low','10_D_Min_Low',\n",
    "                     'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                     '100_D_Avg_Range',\n",
    "                     'Yr_H_Vol','Yr_L_Vol',\n",
    "                     '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                     'Volume','Prev_Volume',\n",
    "                     'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                     'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                     'Prv_8_High','Prv_8_Low',\n",
    "                     'Candlestick_Pattern', 'RSI','upper_bollinger','middle_bollinger','lower_bollinger',\n",
    "                     'Plus_DI','Minus_DI','ADX','MACD','CCI','WILLR'\n",
    "                    ]]\n",
    "        stock_data_us=stock_data_us.append(temp, ignore_index = True)\n",
    "    except Exception as e:\n",
    "        response = requests.post(\n",
    "            url='https://api.telegram.org/bot1216810091:{0}/{1}'.format(token, method),\n",
    "            data={'chat_id': -444135572, 'text': str(e)}).json()\n",
    "#         print(e)\n",
    "#         print(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_stock_data('AXBKY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_stocks_data = pd.merge(stock_data_us, us_stocks, how='left', left_on=['Stock Name'], \n",
    "                                   right_on = [us_stocks.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us_stocks_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to convert dataframe to list for uploading to google sheet\n",
    "us_stocks_data = us_stocks_data[['Stock Name', 'Stock', 'Open','High','Low','Close','Prev Close',\n",
    "                                 'Yr_H_Price','Yr_L_Price','Trend',\n",
    "                                 '200_D_Avg_Close','Prv_200_D_Avg_Close','120_D_Max_Close','50_D_Avg_Close',\n",
    "                                 'Prv_50_D_Avg_Close','Prv_20_D_Avg_Close','20_D_Max_Close','20_D_Avg_Close',\n",
    "                                 '5_D_Max_Close','5_D_Avg_Close','Prv_3_Close','Prv_2_Close',\n",
    "                                 '50_D_Max_High','10_D_Max_High',\n",
    "                                 'Prv_7_High','Prv_6_High','Prv_5_High','Prv_4_High','Prv_3_High','Prv_2_High','Prv_1_High',\n",
    "                                 '50_D_Min_Low','10_D_Min_Low',\n",
    "                                 'Prv_7_Low','Prv_6_Low','Prv_5_Low','Prv_4_Low','Prv_3_Low','Prv_2_Low','Prv_1_Low',\n",
    "                                 '100_D_Avg_Range',\n",
    "                                 'Yr_H_Vol','Yr_L_Vol',\n",
    "                                 '20_D_Avg_Vol','10_D_Avg_Vol','5_D_Avg_Vol',\n",
    "                                 'Volume','Prev_Volume',\n",
    "                                 'Prv_1_Open','Prv_2_Open','Prv_3_Open',\n",
    "                                 'Prv_Yr_H_Price','Prv_Yr_L_Price','Prv_Yr_H_Vol','Prv_Yr_L_Vol',\n",
    "                                 'Prv_8_High','Prv_8_Low',\n",
    "                                 'Candlestick_Pattern', 'RSI','upper_bollinger','middle_bollinger','lower_bollinger',\n",
    "                                 'Plus_DI','Minus_DI','ADX','MACD','CCI','WILLR']]\n",
    "us_stocks_data.rename(columns={\"Stock Name\": \"Symbol\"},inplace=True)\n",
    "us_stocks_data.replace(np.nan,'',inplace = True)\n",
    "\n",
    "us_stocks_data.loc[us_stocks_data['Symbol']=='BRK-A','Symbol'] = 'BRKA'\n",
    "us_stocks_data.loc[us_stocks_data['Symbol']=='BRK-B','Symbol'] = 'BRK.B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_stocks_data.to_excel(excel_writer=\"us_stocks_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient import discovery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gspread\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('stock-scanner-project-75f48f4873c1.json',scope)\n",
    "service = discovery.build('sheets', 'v4', credentials=credentials)\n",
    "gs = service.spreadsheets()\n",
    "spreadsheet_id = '1AkRMRjrD09PL06ZtjDvT5aeuNkbGMyM-Z8jQ01XC7F0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_stocks_data = us_stocks_data.T.reset_index().T.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing list to google sheet\n",
    "response_data = service.spreadsheets().values().update(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        valueInputOption='USER_ENTERED',\n",
    "        range='US_Stocks',\n",
    "        body=dict(\n",
    "            majorDimension='ROWS',\n",
    "            values=us_stocks_data)\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing updated time to google sheet\n",
    "import datetime\n",
    "response_datetime = service.spreadsheets().values().update(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        valueInputOption='USER_ENTERED',\n",
    "        range='US_Stocks!BQ1',\n",
    "        body={\n",
    "            'values': [[datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')]]\n",
    "        }\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\n",
    "    url='https://api.telegram.org/bot1216810091:{0}/{1}'.format(token, method),\n",
    "    data={'chat_id': -444135572, 'text': \"US stock scanning succesful for {0}!\".format(str(date.today()))}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
